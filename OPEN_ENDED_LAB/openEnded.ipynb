{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sV9D74UmUJgJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('mnist_train.csv')\n",
        "test_df = pd.read_csv('mnist_test.csv')"
      ],
      "metadata": {
        "id": "QcGSyI-DX-u4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop('label', axis=1)  # 60,000 × 784\n",
        "y_train = train_df['label']\n",
        "X_test = test_df.drop('label', axis=1)    # 10,000 × 784\n",
        "y_test = test_df['label']"
      ],
      "metadata": {
        "id": "NMVNxoghYH6T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=100),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'MLP (Neural Network)': MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam', max_iter=10)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)  # Train model\n",
        "\n",
        "    y_pred = model.predict(X_test)  # Predict on test data\n",
        "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
        "\n",
        "    print(f'\\n{name} Accuracy: {accuracy:.3f}')\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxKS4dl2Y1V7",
        "outputId": "f1dee28a-ed95-4928-8cc6-0a0b26d1061c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Accuracy: 0.925\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97       980\n",
            "           1       0.97      0.98      0.97      1135\n",
            "           2       0.93      0.90      0.91      1032\n",
            "           3       0.90      0.91      0.91      1010\n",
            "           4       0.93      0.93      0.93       982\n",
            "           5       0.90      0.87      0.89       892\n",
            "           6       0.94      0.95      0.95       958\n",
            "           7       0.93      0.93      0.93      1028\n",
            "           8       0.87      0.89      0.88       974\n",
            "           9       0.91      0.91      0.91      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 963    0    0    3    1    3    4    4    2    0]\n",
            " [   0 1112    4    2    0    1    3    2   11    0]\n",
            " [   3   10  926   15    6    4   15    8   42    3]\n",
            " [   4    1   21  916    1   26    3    9   22    7]\n",
            " [   1    1    7    3  910    0    9    7   10   34]\n",
            " [  11    2    1   33   11  776   11    6   35    6]\n",
            " [   9    3    7    3    7   16  910    2    1    0]\n",
            " [   1    6   24    5    7    1    0  951    3   30]\n",
            " [   8    7    6   23    6   26   10   10  869    9]\n",
            " [   9    7    0   11   25    6    0   22    7  922]]\n",
            "\n",
            "Training KNN...\n",
            "\n",
            "KNN Accuracy: 0.969\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       980\n",
            "           1       0.95      1.00      0.98      1135\n",
            "           2       0.98      0.96      0.97      1032\n",
            "           3       0.96      0.97      0.97      1010\n",
            "           4       0.98      0.96      0.97       982\n",
            "           5       0.97      0.97      0.97       892\n",
            "           6       0.98      0.99      0.98       958\n",
            "           7       0.96      0.96      0.96      1028\n",
            "           8       0.99      0.94      0.96       974\n",
            "           9       0.96      0.95      0.95      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 974    1    1    0    0    1    2    1    0    0]\n",
            " [   0 1133    2    0    0    0    0    0    0    0]\n",
            " [  11    8  991    2    1    0    1   15    3    0]\n",
            " [   0    3    3  976    1   13    1    6    3    4]\n",
            " [   3    7    0    0  944    0    4    2    1   21]\n",
            " [   5    0    0   12    2  862    4    1    2    4]\n",
            " [   5    3    0    0    3    2  945    0    0    0]\n",
            " [   0   22    4    0    3    0    0  988    0   11]\n",
            " [   8    3    5   13    6   12    5    5  913    4]\n",
            " [   5    7    3    9    7    3    1   10    2  962]]\n",
            "\n",
            "Training MLP (Neural Network)...\n",
            "\n",
            "MLP (Neural Network) Accuracy: 0.956\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       980\n",
            "           1       0.99      0.98      0.98      1135\n",
            "           2       0.96      0.94      0.95      1032\n",
            "           3       0.94      0.94      0.94      1010\n",
            "           4       0.95      0.96      0.95       982\n",
            "           5       0.93      0.96      0.95       892\n",
            "           6       0.95      0.97      0.96       958\n",
            "           7       0.96      0.95      0.96      1028\n",
            "           8       0.94      0.95      0.94       974\n",
            "           9       0.96      0.93      0.94      1009\n",
            "\n",
            "    accuracy                           0.96     10000\n",
            "   macro avg       0.96      0.96      0.96     10000\n",
            "weighted avg       0.96      0.96      0.96     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 960    0    2    2    0    2    5    1    4    4]\n",
            " [   0 1113    2    4    0    3    6    2    5    0]\n",
            " [   5    2  974   14    5    0    5   11   14    2]\n",
            " [   1    1    7  950    0   24    1    7   14    5]\n",
            " [   1    0    2    1  939    1   16    5    3   14]\n",
            " [   2    1    0   13    1  857    9    2    6    1]\n",
            " [   6    1    1    1    9   10  925    0    4    1]\n",
            " [   2    5   13    4    7    1    0  981    4   11]\n",
            " [   3    1    5   11    1   14    8    5  922    4]\n",
            " [   5    4    4    8   25    7    0   12    6  938]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    'Logistic Regression': 0.92,  # Example accuracy\n",
        "    'KNN': 0.96,\n",
        "    'MLP (Neural Network)': 0.95\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nU4s986xaT93"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(list(results.keys()), list(results.values()), marker='o', linestyle='-', color='b')\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "GNXDyTedcrkv",
        "outputId": "4bbf45b4-5200-4ee8-b432-5da5ab9724ab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random_search = RandomizedSearchCV(\n",
        " #   LogisticRegression(max_iter=200),\n",
        "  #  param_dist,\n",
        "   # cv=5,\n",
        "    #n_iter=5,  # Reduce trials\n",
        "    #scoring='accuracy',\n",
        "    #random_state=42\n",
        "#)\n",
        "#random_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "ce7BqHLidvZg",
        "outputId": "58f97af2-efbf-471c-c941-82ec4eec8467"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7c547af4724d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1351\u001b[0m             path_func(\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             ]\n\u001b[0;32m--> 451\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    729\u001b[0m                                  **options)\n\u001b[1;32m    730\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    732\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    733\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         loss, grad_pointwise = self.base_loss.loss_gradient(\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mraw_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_prediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/_loss/loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     def loss_gradient(\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}